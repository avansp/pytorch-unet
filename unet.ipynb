{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla U-Net\n",
    "----\n",
    "\n",
    "As described by [Ronneberger's MICCAI 2015 paper](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(f\"Using device:{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A double convolution block\n",
    "\n",
    "Each stage in the U-Net, there are twice convolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ==> conv ==> BN ==> relu ==> conv ==> BN ==> relu ==>\n",
    "    in_channels --> out_channels --> out_channels\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.out_image = None\n",
    "        \n",
    "    def forward(self, in_image):\n",
    "        self.out_image = self.model(in_image)\n",
    "        return self.out_image\n",
    "    \n",
    "    def get_output(self):\n",
    "        return self.out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 128, 282, 282]          73,856\n",
      "       BatchNorm2d-2        [-1, 128, 282, 282]             256\n",
      "              ReLU-3        [-1, 128, 282, 282]               0\n",
      "            Conv2d-4        [-1, 128, 280, 280]         147,584\n",
      "       BatchNorm2d-5        [-1, 128, 280, 280]             256\n",
      "              ReLU-6        [-1, 128, 280, 280]               0\n",
      "================================================================\n",
      "Total params: 221,952\n",
      "Trainable params: 221,952\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 19.69\n",
      "Forward/backward pass size (MB): 462.67\n",
      "Params size (MB): 0.85\n",
      "Estimated Total Size (MB): 483.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(DoubleConvBlock(64,128).to(device), (64, 284, 284))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down sampling\n",
    "\n",
    "At the encoding side (down sampling), it uses max pooling layer and then pass the output to the double convolution block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampleBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    (in_channel) ==> MaxPool\n",
    "                        |\n",
    "                        ==> DoubleConvBlock ==> (out_channel)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(DownSampleBlock, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            DoubleConvBlock(in_channel, out_channel)\n",
    "        )\n",
    "        \n",
    "    def forward(self, in_image):\n",
    "        return self.model(in_image)\n",
    "    \n",
    "    def get_output(self):\n",
    "        return self.model[1].get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         MaxPool2d-1         [-1, 64, 284, 284]               0\n",
      "            Conv2d-2        [-1, 128, 282, 282]          73,856\n",
      "       BatchNorm2d-3        [-1, 128, 282, 282]             256\n",
      "              ReLU-4        [-1, 128, 282, 282]               0\n",
      "            Conv2d-5        [-1, 128, 280, 280]         147,584\n",
      "       BatchNorm2d-6        [-1, 128, 280, 280]             256\n",
      "              ReLU-7        [-1, 128, 280, 280]               0\n",
      "   DoubleConvBlock-8        [-1, 128, 280, 280]               0\n",
      "================================================================\n",
      "Total params: 221,952\n",
      "Trainable params: 221,952\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 78.77\n",
      "Forward/backward pass size (MB): 578.61\n",
      "Params size (MB): 0.85\n",
      "Estimated Total Size (MB): 658.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(DownSampleBlock(64, 128).to(device), (64, 568, 568))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up sampling\n",
    "\n",
    "At the decoding side, there is up sampling layer (ConvTranspose2d or Upsample), concat it with the output from the encoding side using a skip connection, then pass it to another DoubleConvBlock. Hence, the forward function contains 2 input arguments: the input image and the skip image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    up-sampling ==> concat ==> double-convolution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channel):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "        \n",
    "        self.skip_image = None\n",
    "        self.up_sample = nn.ConvTranspose2d(in_channel, in_channel//2, kernel_size=2, stride=2)\n",
    "        self.double_conv = DoubleConvBlock(in_channel, in_channel//2)\n",
    "        \n",
    "    def forward(self, in_image, skip_image):\n",
    "        \n",
    "        # up sample the input image\n",
    "        out_image = self.up_sample(in_image)\n",
    "        \n",
    "        # skip image has additional pad size due to ConvTranspose2d output\n",
    "        pad_size = [\n",
    "            item for sublist in \n",
    "            torch.tensor(out_image.shape[-2:]) - torch.tensor(skip_image.shape[-2:]) \n",
    "            for item in [sublist.item() // 2] * 2]\n",
    "        \n",
    "        # the concatenation\n",
    "        out_image = torch.cat((F.pad(skip_image, pad_size), out_image), dim=1)\n",
    "        \n",
    "        # pass through the convolution\n",
    "        out_image = self.double_conv(out_image)\n",
    "        \n",
    "        return out_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1          [-1, 512, 56, 56]       2,097,664\n",
      "            Conv2d-2          [-1, 512, 54, 54]       4,719,104\n",
      "       BatchNorm2d-3          [-1, 512, 54, 54]           1,024\n",
      "              ReLU-4          [-1, 512, 54, 54]               0\n",
      "            Conv2d-5          [-1, 512, 52, 52]       2,359,808\n",
      "       BatchNorm2d-6          [-1, 512, 52, 52]           1,024\n",
      "              ReLU-7          [-1, 512, 52, 52]               0\n",
      "   DoubleConvBlock-8          [-1, 512, 52, 52]               0\n",
      "================================================================\n",
      "Total params: 9,178,624\n",
      "Trainable params: 9,178,624\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 6422528.00\n",
      "Forward/backward pass size (MB): 88.67\n",
      "Params size (MB): 35.01\n",
      "Estimated Total Size (MB): 6422651.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(UpSampleBlock(1024).to(device), [(1024, 28, 28), (512, 64, 64)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stiching up\n",
    "\n",
    "Finally, we stich them all together creating the final U-Net architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoding: DoubleConvEncoder + 4 * DownSample\n",
    "    Decoding:\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channel=1, out_channel=2):\n",
    "        \"\"\"\n",
    "        Strict from Rossenberger's UNet: input = 1 (greyscale), output = 2 (mask)\n",
    "        \"\"\"\n",
    "        super(VanillaUNet, self).__init__()\n",
    "        \n",
    "        self.layer_names = ['layer_1', 'layer_2', 'layer_3', 'layer_4', 'layer_5']\n",
    "        \n",
    "        self.encoders = nn.ModuleDict([\n",
    "            (name, block(ic, oc)) for name, block, ic, oc in zip(\n",
    "                self.layer_names, \n",
    "                [DoubleConvBlock, DownSampleBlock, DownSampleBlock, \n",
    "                 DownSampleBlock, DownSampleBlock],\n",
    "                [in_channel, 64, 128, 256, 512],\n",
    "                [64, 128, 256, 512, 1024]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.decoders = nn.ModuleDict([\n",
    "            (name, UpSampleBlock(ic)) for name, ic in zip(\n",
    "                self.layer_names,\n",
    "                [128, 256, 512, 1024]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.output_layer = nn.Conv2d(64, 2, kernel_size=1)\n",
    "        \n",
    "    def forward(self, in_image):\n",
    "        out_image = in_image\n",
    "        \n",
    "        # encoding\n",
    "        for k in self.layer_names:\n",
    "            out_image = self.encoders[k](out_image)\n",
    "            \n",
    "        # decoding (from the back)\n",
    "        for k in list(self.decoders.keys())[len(self.decoders)::-1]:\n",
    "            out_image = self.decoders[k](out_image, self.encoders[k].get_output())\n",
    "            \n",
    "        # final layer\n",
    "        out_image = self.output_layer(out_image)\n",
    "        \n",
    "        return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 570, 570]             640\n",
      "       BatchNorm2d-2         [-1, 64, 570, 570]             128\n",
      "              ReLU-3         [-1, 64, 570, 570]               0\n",
      "            Conv2d-4         [-1, 64, 568, 568]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 568, 568]             128\n",
      "              ReLU-6         [-1, 64, 568, 568]               0\n",
      "   DoubleConvBlock-7         [-1, 64, 568, 568]               0\n",
      "         MaxPool2d-8         [-1, 64, 284, 284]               0\n",
      "            Conv2d-9        [-1, 128, 282, 282]          73,856\n",
      "      BatchNorm2d-10        [-1, 128, 282, 282]             256\n",
      "             ReLU-11        [-1, 128, 282, 282]               0\n",
      "           Conv2d-12        [-1, 128, 280, 280]         147,584\n",
      "      BatchNorm2d-13        [-1, 128, 280, 280]             256\n",
      "             ReLU-14        [-1, 128, 280, 280]               0\n",
      "  DoubleConvBlock-15        [-1, 128, 280, 280]               0\n",
      "  DownSampleBlock-16        [-1, 128, 280, 280]               0\n",
      "        MaxPool2d-17        [-1, 128, 140, 140]               0\n",
      "           Conv2d-18        [-1, 256, 138, 138]         295,168\n",
      "      BatchNorm2d-19        [-1, 256, 138, 138]             512\n",
      "             ReLU-20        [-1, 256, 138, 138]               0\n",
      "           Conv2d-21        [-1, 256, 136, 136]         590,080\n",
      "      BatchNorm2d-22        [-1, 256, 136, 136]             512\n",
      "             ReLU-23        [-1, 256, 136, 136]               0\n",
      "  DoubleConvBlock-24        [-1, 256, 136, 136]               0\n",
      "  DownSampleBlock-25        [-1, 256, 136, 136]               0\n",
      "        MaxPool2d-26          [-1, 256, 68, 68]               0\n",
      "           Conv2d-27          [-1, 512, 66, 66]       1,180,160\n",
      "      BatchNorm2d-28          [-1, 512, 66, 66]           1,024\n",
      "             ReLU-29          [-1, 512, 66, 66]               0\n",
      "           Conv2d-30          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-31          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-32          [-1, 512, 64, 64]               0\n",
      "  DoubleConvBlock-33          [-1, 512, 64, 64]               0\n",
      "  DownSampleBlock-34          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-35          [-1, 512, 32, 32]               0\n",
      "           Conv2d-36         [-1, 1024, 30, 30]       4,719,616\n",
      "      BatchNorm2d-37         [-1, 1024, 30, 30]           2,048\n",
      "             ReLU-38         [-1, 1024, 30, 30]               0\n",
      "           Conv2d-39         [-1, 1024, 28, 28]       9,438,208\n",
      "      BatchNorm2d-40         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-41         [-1, 1024, 28, 28]               0\n",
      "  DoubleConvBlock-42         [-1, 1024, 28, 28]               0\n",
      "  DownSampleBlock-43         [-1, 1024, 28, 28]               0\n",
      "  ConvTranspose2d-44          [-1, 512, 56, 56]       2,097,664\n",
      "           Conv2d-45          [-1, 512, 54, 54]       4,719,104\n",
      "      BatchNorm2d-46          [-1, 512, 54, 54]           1,024\n",
      "             ReLU-47          [-1, 512, 54, 54]               0\n",
      "           Conv2d-48          [-1, 512, 52, 52]       2,359,808\n",
      "      BatchNorm2d-49          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-50          [-1, 512, 52, 52]               0\n",
      "  DoubleConvBlock-51          [-1, 512, 52, 52]               0\n",
      "    UpSampleBlock-52          [-1, 512, 52, 52]               0\n",
      "  ConvTranspose2d-53        [-1, 256, 104, 104]         524,544\n",
      "           Conv2d-54        [-1, 256, 102, 102]       1,179,904\n",
      "      BatchNorm2d-55        [-1, 256, 102, 102]             512\n",
      "             ReLU-56        [-1, 256, 102, 102]               0\n",
      "           Conv2d-57        [-1, 256, 100, 100]         590,080\n",
      "      BatchNorm2d-58        [-1, 256, 100, 100]             512\n",
      "             ReLU-59        [-1, 256, 100, 100]               0\n",
      "  DoubleConvBlock-60        [-1, 256, 100, 100]               0\n",
      "    UpSampleBlock-61        [-1, 256, 100, 100]               0\n",
      "  ConvTranspose2d-62        [-1, 128, 200, 200]         131,200\n",
      "           Conv2d-63        [-1, 128, 198, 198]         295,040\n",
      "      BatchNorm2d-64        [-1, 128, 198, 198]             256\n",
      "             ReLU-65        [-1, 128, 198, 198]               0\n",
      "           Conv2d-66        [-1, 128, 196, 196]         147,584\n",
      "      BatchNorm2d-67        [-1, 128, 196, 196]             256\n",
      "             ReLU-68        [-1, 128, 196, 196]               0\n",
      "  DoubleConvBlock-69        [-1, 128, 196, 196]               0\n",
      "    UpSampleBlock-70        [-1, 128, 196, 196]               0\n",
      "  ConvTranspose2d-71         [-1, 64, 392, 392]          32,832\n",
      "           Conv2d-72         [-1, 64, 390, 390]          73,792\n",
      "      BatchNorm2d-73         [-1, 64, 390, 390]             128\n",
      "             ReLU-74         [-1, 64, 390, 390]               0\n",
      "           Conv2d-75         [-1, 64, 388, 388]          36,928\n",
      "      BatchNorm2d-76         [-1, 64, 388, 388]             128\n",
      "             ReLU-77         [-1, 64, 388, 388]               0\n",
      "  DoubleConvBlock-78         [-1, 64, 388, 388]               0\n",
      "    UpSampleBlock-79         [-1, 64, 388, 388]               0\n",
      "           Conv2d-80          [-1, 2, 388, 388]             130\n",
      "================================================================\n",
      "Total params: 31,042,434\n",
      "Trainable params: 31,042,434\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.25\n",
      "Forward/backward pass size (MB): 3556.52\n",
      "Params size (MB): 118.42\n",
      "Estimated Total Size (MB): 3676.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(VanillaUNet().to(device), (1, 572, 572))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
