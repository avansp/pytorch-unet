{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla UNet on the Carvana image dataset\n",
    "----\n",
    "\n",
    "Data: https://www.kaggle.com/c/carvana-image-masking-challenge/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "import unet\n",
    "from image_dataset import ImageMaskDataset\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')\n",
    "ncpus = mp.cpu_count()\n",
    "print(f'Using {ncpus} cpu''s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaUNetCarvana:\n",
    "    \n",
    "    BATCH_SIZE = 4\n",
    "    LEARNING_RATE = 0.1\n",
    "    PAD_SIZE = (572-388) // 2\n",
    "    \n",
    "    def __init__(self, \n",
    "                 root_path, \n",
    "                 chk_folder,\n",
    "                 split=[0.7, 0.2, 0.1]):\n",
    "        \n",
    "        # The problem with this Vanilla Ronnenberger UNet, the input and output size does\n",
    "        # not match. Input is (572,572), output is (388,388).\n",
    "        # To make the loss function works properly, the dataset will create 388x388 image & masks.\n",
    "        # Then pad the image to get 572x572 size before feeding it to the network.\n",
    "        ds = ImageMaskDataset.from_folder(\n",
    "            size=(388,388),\n",
    "            image_folder=os.path.join(root_path, 'train'),\n",
    "            image_pattern='*.jpg',\n",
    "            mask_fname_fun=lambda x: os.path.join(\n",
    "                root_path, 'train_masks', x.replace('.jpg', '_mask.gif'))\n",
    "        )\n",
    "        print(f'The total number of images in the dataset: {len(ds)}')\n",
    "        \n",
    "        # we're going to split the dataset into training & test\n",
    "        n_split = [int(item * len(ds)) for item in split]\n",
    "        if sum(n_split)<len(ds):\n",
    "            n_split[-1] += len(ds) - sum(n_split)\n",
    "        assert sum(n_split)==len(ds), \"Sum of split must equal to 1.0\"\n",
    "        \n",
    "        # split\n",
    "        sub_ds = random_split(ds, n_split)\n",
    "        \n",
    "        # create data loader\n",
    "        self.train_loader = DataLoader(\n",
    "            sub_ds[0], batch_size=self.BATCH_SIZE, shuffle=True, num_workers=ncpus, pin_memory=True\n",
    "        )\n",
    "        print(f\"Training samples are {len(sub_ds[0])} or {100.0*len(sub_ds[0])/len(ds):.2f}%\")\n",
    "        self.val_loader = DataLoader(\n",
    "            sub_ds[1], batch_size=self.BATCH_SIZE, shuffle=True, num_workers=ncpus, pin_memory=True\n",
    "        )\n",
    "        print(f\"Validation samples are {len(sub_ds[1])} or {100.0*len(sub_ds[1])/len(ds):.2f}%\")\n",
    "        self.test_loader = DataLoader(\n",
    "            sub_ds[2], batch_size=self.BATCH_SIZE, shuffle=False, num_workers=ncpus, pin_memory=True\n",
    "        )\n",
    "        print(f\"Test samples are {len(sub_ds[2])} or {100.0*len(sub_ds[2])/len(ds):.2f}%\")\n",
    "        \n",
    "        # create the model\n",
    "        self.model = unet.VanillaUNet(3, 2).to(device)\n",
    "        \n",
    "        # optimizers & criterion\n",
    "        self.optimizer = torch.optim.RMSprop(self.model.parameters(), \n",
    "                                             lr=self.LEARNING_RATE,\n",
    "                                             weight_decay=1e-8, momentum=0.9)\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        # checkpoints\n",
    "        if not os.path.isdir(chk_folder):\n",
    "            os.makedirs(chk_folder)\n",
    "        self.chk_folder = chk_folder\n",
    "        logging.basicConfig(\n",
    "            filename=os.path.join(self.chk_folder, 'training.log'),\n",
    "            level=logging.DEBUG)\n",
    "        \n",
    "    def train(self, num_epoch):\n",
    "        \n",
    "        logging.info('Start training:')\n",
    "        logging.info(f'  Number of epochs:            {num_epoch}')\n",
    "        logging.info(f'  Batch size:                  {self.BATCH_SIZE}')\n",
    "        logging.info(f'  Learning rate:               {self.LEARNING_RATE}')\n",
    "        logging.info(f'  Training/Validate/Test size: {len(self.train_loader)}/{len(self.val_loader)}/{len(self.test_loader)}')\n",
    "        \n",
    "        for epoch in range(num_epoch):\n",
    "            # 1. Don't forget to set training mode for the model\n",
    "            self.model.train()\n",
    "            \n",
    "            with tqdm(total=len(self.train_loader.dataset)) as pbar:\n",
    "            \n",
    "                last_loss = 0.00\n",
    "                for step, (img, mask) in enumerate(self.train_loader):\n",
    "                    # 2. Adjust the device. Otherwise it will raise unmatching type error.\n",
    "                    img = img.to(device)\n",
    "                    mask_true = mask.to(device)\n",
    "\n",
    "                    # 2.5 Add the input image to get 572x572. Leave the mask_true\n",
    "                    img = torch.nn.functional.pad(img, ([self.PAD_SIZE] * 4))\n",
    "\n",
    "                    # 3. Predict\n",
    "                    mask_pred = self.model(img)\n",
    "\n",
    "                    # 4. Calculate the loss\n",
    "                    loss = self.criterion(mask_pred, mask_true)\n",
    "                    loss_diff = loss.item() - last_loss\n",
    "                    last_loss = loss.item()\n",
    "\n",
    "                    # 5. Backward processing\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 6. Then forward step\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    # update the progress bar\n",
    "                    pbar.set_description(f\"Epoch {epoch}\")\n",
    "                    pbar.set_postfix(\n",
    "                        loss=f\"{loss.item():.2f} ({loss_diff:.1f})\"\n",
    "                    )\n",
    "                    pbar.update(n=img.shape[0])\n",
    "                \n",
    "        print(\"FINISHED TRAINING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vunc = VanillaUNetCarvana(r'/tmp/carvana/', r'/tmp/chkpts/carvana/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred, mask_true = vunc.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
